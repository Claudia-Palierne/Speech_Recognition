{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1MPivN4HEjJ","outputId":"c9e133e7-9b58-4a0b-c6cd-3debb946fb75","executionInfo":{"status":"ok","timestamp":1689678916311,"user_tz":-180,"elapsed":8363,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_io\n","  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.32.0)\n","Installing collected packages: tensorflow_io\n","Successfully installed tensorflow_io-0.32.0\n"]}],"source":["!pip install tensorflow_io"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wqur42BLZEq3"},"outputs":[],"source":["import os\n","import wave\n","import librosa\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import IPython.display as ipd\n","import tensorflow as tf\n","import tensorflow_io as tfio\n","from functools import reduce"]},{"cell_type":"markdown","metadata":{"id":"49nqFdV8Af7g"},"source":["# Speech Recognition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAIDWjjAAnKs"},"outputs":[],"source":["# path = 'drive/MyDrive/Kaggle/speech_recognition/'\n","\n","path = '/content/gdrive/MyDrive/speech_recognition/'\n","classes = ['yes', 'no', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'up', 'down']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5ARNKkPVtjf","outputId":"0ed99342-f1a8-4ef7-9651-5eab53a4a57e","executionInfo":{"status":"ok","timestamp":1689678949523,"user_tz":-180,"elapsed":20270,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"vgmJV9NX-jIa"},"source":["# Building dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rCkMSM1lGMD"},"outputs":[],"source":["# Define Paths to labeled data and Split into Train, Validation and Test using Kaggle split\n","tf_dic_train = {}\n","tf_dic_val = {}\n","tf_dic_test = {}\n","FILES_TO_LOAD = 500\n","\n","with open(os.path.join(path + \"/testing_list.txt\"), 'r') as file:\n","    test_names = file.read().splitlines()\n","with open(os.path.join(path + \"/validation_list.txt\"), 'r') as file:\n","    val_names = file.read().splitlines()\n","\n","for i, label in enumerate(classes):\n","  train_tmp = []\n","  val_tmp = []\n","  test_tmp = []\n","  for filename in os.listdir(os.path.join(path + label)):\n","    if \"/\".join([label, filename]) in test_names:\n","      if len(test_tmp) >= FILES_TO_LOAD*0.1:\n","        pass\n","      else:\n","        test_tmp.append(os.path.join(path + label + \"/\" + filename))\n","    elif \"/\".join([label, filename]) in val_names:\n","      if len(val_tmp) >= FILES_TO_LOAD*0.1:\n","        pass\n","      else:\n","        val_tmp.append(os.path.join(path + label + \"/\" + filename))\n","    else:\n","      if len(train_tmp) >= FILES_TO_LOAD*0.8:\n","        pass\n","      else:\n","        train_tmp.append(os.path.join(path + label + \"/\" + filename))\n","\n","  train_tmp_tf = tf.data.Dataset.list_files(train_tmp)\n","  val_tmp_tf = tf.data.Dataset.list_files(val_tmp)\n","  test_tmp_tf = tf.data.Dataset.list_files(test_tmp)\n","\n","  tf_dic_train[label] = tf.data.Dataset.zip((train_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(train_tmp_tf),), i))))\n","  tf_dic_val[label] = tf.data.Dataset.zip((val_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(val_tmp_tf),), i))))\n","  tf_dic_test[label] = tf.data.Dataset.zip((test_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(test_tmp_tf),), i))))\n","\n","datasets_train = list(tf_dic_train.values())\n","datasets_val = list(tf_dic_val.values())\n","datasets_test = list(tf_dic_test.values())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeOND8VnxWAi"},"outputs":[],"source":["def dataset_reduce(datasets):\n","  merged_dataset_reduce = reduce(lambda d1, d2: d1.concatenate(d2), datasets)\n","  return merged_dataset_reduce.shuffle(buffer_size=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qp88sR5exlkC"},"outputs":[],"source":["datasets_train = dataset_reduce(datasets_train)\n","datasets_val = dataset_reduce(datasets_val)\n","datasets_test = dataset_reduce(datasets_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApnE-Lh_yCc-","outputId":"b9b57e05-74b6-491f-8e4a-b75b9ac5f273","executionInfo":{"status":"ok","timestamp":1689679046231,"user_tz":-180,"elapsed":408,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5171, 650, 650)"]},"metadata":{},"execution_count":8}],"source":["len(datasets_train), len(datasets_val), len(datasets_test)"]},{"cell_type":"markdown","metadata":{"id":"_gNU6oDy-dRt"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDwJKqP-veEG"},"outputs":[],"source":["def load_wav_16k_mono(filename):\n","    # Load encoded wav file\n","    file_contents = tf.io.read_file(filename)\n","    # Decode wav (tensors by channels)\n","    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n","    # Removes trailing axis\n","    wav = tf.squeeze(wav, axis=-1)\n","    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n","    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n","    return wav"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3nFfroB3j1a"},"outputs":[],"source":["# Load padding wav file from _noice folder (/content/gdrive/MyDrive/speech_recognition/_noise/dude_miaowing.wav)\n","padding_file = '/content/gdrive/MyDrive/speech_recognition/_noise/dude_miaowing.wav'\n","padding_contents = tf.io.read_file(padding_file)\n","padding_waveform, _ = tf.audio.decode_wav(padding_contents, desired_channels=1)\n","padding_waveform = tf.squeeze(padding_waveform, axis=-1)"]},{"cell_type":"code","source":["# Load noise wav file from _noice folder (/content/gdrive/MyDrive/speech_recognition/_noise/white_noise.wav) - for  blending in\n","blend_file = '/content/gdrive/MyDrive/speech_recognition/_noise/white_noise.wav'\n","blend_contents = tf.io.read_file(blend_file)\n","blend_waveform, _ = tf.audio.decode_wav(blend_contents, desired_channels=1)\n","blend_waveform = tf.squeeze(blend_waveform, axis=-1)"],"metadata":{"id":"QgBsEpuvpagk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48W8Ev9yPOns"},"outputs":[],"source":["def preprocess_multy(file_path, label):\n","    wav = load_wav_16k_mono(file_path)\n","    wav = wav[:16000]\n","\n","    # Calculate difference in length\n","    target_length = 16000\n","    current_length = tf.shape(wav)[0]\n","    pad_length = target_length - current_length\n","\n","    # Pad waveform if it is shorter than the target length\n","    if pad_length > 0:\n","        padding_start = tf.random.uniform(shape=[], minval=0, maxval=padding_waveform.shape[0] - pad_length, dtype=tf.int32)\n","        padding_slice = padding_waveform[padding_start : padding_start + pad_length]\n","\n","        # Pad the waveform with the selected slice\n","        wav = tf.concat([wav, padding_slice], axis=0)\n","\n","    # Blend in white noise\n","    blended_wav = wav + blend_waveform[:16000] * 0.3\n","\n","    spectrogram = tf.signal.stft(blended_wav, frame_length=320, frame_step=32)\n","    spectrogram = tf.abs(spectrogram)\n","    spectrogram = tf.expand_dims(spectrogram, axis=2)\n","\n","    return spectrogram, tf.one_hot(label, 13)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1DC4ZrfPP0_","outputId":"95ecc183-bf26-4f77-838a-47ba2881ca51","executionInfo":{"status":"ok","timestamp":1689679062485,"user_tz":-180,"elapsed":747,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"]}],"source":["# Train data:\n","train_data = datasets_train.map(preprocess_multy)\n","train_data = train_data.cache()\n","train_data = train_data.batch(32)\n","train_data = train_data.prefetch(16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5E5nWR3N5M-W","outputId":"144d0eca-4544-4bde-de3f-6e20420e8225","executionInfo":{"status":"ok","timestamp":1689679065343,"user_tz":-180,"elapsed":340,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"]}],"source":["# Validation data:\n","val_data = datasets_val.map(preprocess_multy)\n","val_data = val_data.cache()\n","val_data = val_data.batch(32)\n","val_data = val_data.prefetch(16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nilWusoI5ZUV","outputId":"2eb18838-e9e2-4657-9ba9-babe6770b56a","executionInfo":{"status":"ok","timestamp":1689679074625,"user_tz":-180,"elapsed":929,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"]}],"source":["# Test data:\n","test_data = datasets_test.map(preprocess_multy)\n","test_data = test_data.cache()\n","# test_data = test_data.shuffle(buffer_size=1000)\n","test_data = test_data.batch(32)\n","test_data = test_data.prefetch(16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9P_zV44143yj","outputId":"f9cb6559-bfb0-4c2d-a0b5-dcca870376b4","executionInfo":{"status":"ok","timestamp":1689679076791,"user_tz":-180,"elapsed":3,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(162, 21, 21)"]},"metadata":{},"execution_count":16}],"source":["len(train_data), len(val_data), len(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cA9AQKXIRbCZ","outputId":"335f6349-5257-4990-996d-15a2fe5c55ef","executionInfo":{"status":"ok","timestamp":1689679094888,"user_tz":-180,"elapsed":14845,"user":{"displayName":"Maria Blinchevskaya","userId":"09259427132122827922"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 128, 64, 1), (32, 13))"]},"metadata":{},"execution_count":17}],"source":["samples, labels = train_data.as_numpy_iterator().next()\n","samples.shape, labels.shape"]},{"cell_type":"code","source":[],"metadata":{"id":"xlci-RJvvMW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cXC9goeIvMf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5iowIl5qvMpR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1f8Goc4J28jOhNuDpwrbQb8nxEJAcvX-X","timestamp":1689679251902},{"file_id":"1rgLYJ57MSLKkFC936IC2pnRAVKJ3gk8W","timestamp":1689593875713}],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}