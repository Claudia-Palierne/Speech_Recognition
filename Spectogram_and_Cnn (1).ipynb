{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1MPivN4HEjJ",
        "outputId": "7270c8b6-cb7d-4389-81d8-1b8b30c4e964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.32.0)\n",
            "Installing collected packages: tensorflow_io\n",
            "Successfully installed tensorflow_io-0.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqur42BLZEq3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wave\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import IPython.display as ipd\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nqFdV8Af7g"
      },
      "source": [
        "# Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAIDWjjAAnKs"
      },
      "outputs": [],
      "source": [
        "# path = 'drive/MyDrive/Kaggle/speech_recognition/'\n",
        "\n",
        "path = '/content/gdrive/MyDrive/Final_Project/speech_recognition/'\n",
        "classes = ['yes', 'no', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'up', 'down']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ARNKkPVtjf",
        "outputId": "4ceaba61-6595-4f1c-c393-926fa04c8192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgmJV9NX-jIa"
      },
      "source": [
        "# Building dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rCkMSM1lGMD"
      },
      "outputs": [],
      "source": [
        "# Define Paths to labeled data and Split into Train, Validation and Test using Kaggle split\n",
        "tf_dic_train = {}\n",
        "tf_dic_val = {}\n",
        "tf_dic_test = {}\n",
        "FILES_TO_LOAD = 500\n",
        "\n",
        "with open(os.path.join(path + \"/testing_list.txt\"), 'r') as file:\n",
        "    test_names = file.read().splitlines()\n",
        "with open(os.path.join(path + \"/validation_list.txt\"), 'r') as file:\n",
        "    val_names = file.read().splitlines()\n",
        "\n",
        "for i, label in enumerate(classes):\n",
        "  train_tmp = []\n",
        "  val_tmp = []\n",
        "  test_tmp = []\n",
        "  for filename in os.listdir(os.path.join(path + label)):\n",
        "    if \"/\".join([label, filename]) in test_names:\n",
        "      if len(test_tmp) >= FILES_TO_LOAD*0.1:\n",
        "        pass\n",
        "      else:\n",
        "        test_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "    elif \"/\".join([label, filename]) in val_names:\n",
        "      if len(val_tmp) >= FILES_TO_LOAD*0.1:\n",
        "        pass\n",
        "      else:\n",
        "        val_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "    else:\n",
        "      if len(train_tmp) >= FILES_TO_LOAD*0.8:\n",
        "        pass\n",
        "      else:\n",
        "        train_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "\n",
        "  train_tmp_tf = tf.data.Dataset.list_files(train_tmp)\n",
        "  val_tmp_tf = tf.data.Dataset.list_files(val_tmp)\n",
        "  test_tmp_tf = tf.data.Dataset.list_files(test_tmp)\n",
        "\n",
        "  tf_dic_train[label] = tf.data.Dataset.zip((train_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(train_tmp_tf),), i))))\n",
        "  tf_dic_val[label] = tf.data.Dataset.zip((val_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(val_tmp_tf),), i))))\n",
        "  tf_dic_test[label] = tf.data.Dataset.zip((test_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(test_tmp_tf),), i))))\n",
        "\n",
        "datasets_train = list(tf_dic_train.values())\n",
        "datasets_val = list(tf_dic_val.values())\n",
        "datasets_test = list(tf_dic_test.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeOND8VnxWAi"
      },
      "outputs": [],
      "source": [
        "def dataset_reduce(datasets):\n",
        "  merged_dataset_reduce = reduce(lambda d1, d2: d1.concatenate(d2), datasets)\n",
        "  return merged_dataset_reduce.shuffle(buffer_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp88sR5exlkC"
      },
      "outputs": [],
      "source": [
        "datasets_train = dataset_reduce(datasets_train)\n",
        "datasets_val = dataset_reduce(datasets_val)\n",
        "datasets_test = dataset_reduce(datasets_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApnE-Lh_yCc-",
        "outputId": "77d77e9c-bb76-433d-dc7a-b9a0ccc21c29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5171, 650, 650)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(datasets_train), len(datasets_val), len(datasets_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gNU6oDy-dRt"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDwJKqP-veEG"
      },
      "outputs": [],
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels)\n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3nFfroB3j1a"
      },
      "outputs": [],
      "source": [
        "# Load padding wav file from _noice folder (/content/gdrive/MyDrive/speech_recognition/_noise/dude_miaowing.wav)\n",
        "padding_file = '/content/gdrive/MyDrive/Final_Project/speech_recognition/_noise/dude_miaowing.wav'\n",
        "padding_contents = tf.io.read_file(padding_file)\n",
        "padding_waveform, _ = tf.audio.decode_wav(padding_contents, desired_channels=1)\n",
        "padding_waveform = tf.squeeze(padding_waveform, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48W8Ev9yPOns"
      },
      "outputs": [],
      "source": [
        "def preprocess_multy(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:16000]\n",
        "\n",
        "    # Calculate difference in length\n",
        "    target_length = 16000\n",
        "    current_length = tf.shape(wav)[0]\n",
        "    pad_length = target_length - current_length\n",
        "\n",
        "    # Pad waveform if it is shorter than the target length\n",
        "    if pad_length > 0:\n",
        "        padding_start = tf.random.uniform(shape=[], minval=0, maxval=padding_waveform.shape[0] - pad_length, dtype=tf.int32)\n",
        "        padding_slice = padding_waveform[padding_start : padding_start + pad_length]\n",
        "\n",
        "        # Pad the waveform with the selected slice\n",
        "        wav = tf.concat([wav, padding_slice], axis=0)\n",
        "\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, tf.one_hot(label, 13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1DC4ZrfPP0_",
        "outputId": "ede6f180-1fdb-408c-e568-8dbf915cfbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "# Train data:\n",
        "train_data = datasets_train.map(preprocess_multy)\n",
        "train_data = train_data.cache()\n",
        "train_data = train_data.shuffle(buffer_size=1000)\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5nWR3N5M-W",
        "outputId": "530c1f2e-db0c-40bf-97e1-c9b1ea02d836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "# Validation data:\n",
        "val_data = datasets_val.map(preprocess_multy)\n",
        "val_data = val_data.cache()\n",
        "val_data = val_data.shuffle(buffer_size=1000)\n",
        "val_data = val_data.batch(16)\n",
        "val_data = val_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilWusoI5ZUV",
        "outputId": "cc14f1a8-5725-4558-93a9-2c0417ed1689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "# Test data:\n",
        "test_data = datasets_test.map(preprocess_multy)\n",
        "test_data = test_data.cache()\n",
        "test_data = test_data.shuffle(buffer_size=1000)\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P_zV44143yj",
        "outputId": "b026126c-4c36-4b54-bc97-90e64afcdaec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(324, 41, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_data), len(val_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA9AQKXIRbCZ",
        "outputId": "25a638a3-4721-4749-d0d9-66d3e7f18b8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 491, 257, 1), (16, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "samples, labels = train_data.as_numpy_iterator().next()\n",
        "samples.shape, labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LXKgdqCJfIt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.metrics import precision_score, make_scorer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3APmuWnUwD3"
      },
      "outputs": [],
      "source": [
        "base_model = Sequential()\n",
        "base_model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(491, 257, 1)))\n",
        "base_model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "base_model.add(Flatten())\n",
        "base_model.add(Dense(128, activation='relu'))\n",
        "base_model.add(Dense(13, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeOnnp4qUwbG"
      },
      "outputs": [],
      "source": [
        "base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoTIBO9AUx_4",
        "outputId": "9d738d8a-b712-49a1-ef8e-6f82aa0c5b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 489, 255, 16)      160       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 487, 253, 16)      2320      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1971376)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               252336256 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 13)                1677      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252,340,413\n",
            "Trainable params: 252,340,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIeEdVHmUz3f",
        "outputId": "12babd99-e6a6-4b2e-f343-66e22d8537a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "324/324 [==============================] - 1987s 6s/step - loss: 0.2500 - recall_1: 0.2106 - precision_1: 0.5545 - val_loss: 0.2269 - val_recall_1: 0.3246 - val_precision_1: 0.5172\n",
            "Epoch 2/4\n",
            "324/324 [==============================] - 29s 91ms/step - loss: 0.1134 - recall_1: 0.5701 - precision_1: 0.8420 - val_loss: 0.2053 - val_recall_1: 0.3754 - val_precision_1: 0.6272\n",
            "Epoch 3/4\n",
            "324/324 [==============================] - 30s 91ms/step - loss: 0.0688 - recall_1: 0.7960 - precision_1: 0.9009 - val_loss: 0.2622 - val_recall_1: 0.3600 - val_precision_1: 0.7048\n",
            "Epoch 4/4\n",
            "324/324 [==============================] - 30s 93ms/step - loss: 0.0402 - recall_1: 0.8888 - precision_1: 0.9571 - val_loss: 0.3053 - val_recall_1: 0.4554 - val_precision_1: 0.6338\n"
          ]
        }
      ],
      "source": [
        "hist = base_model.fit(train_data, validation_data=val_data, epochs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "xAqJmNlMVVE2",
        "outputId": "f3a7e296-ba68-4069-9dce-45807b91fb4c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dce2b8759b78>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Final_Project/speech_recognition/baseline_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ],
      "source": [
        "base_model.save('/content/gdrive/MyDrive/Final_Project/speech_recognition/baseline_4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8HK_1tqjp1h"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "base_model_loaded = load_model('/content/gdrive/MyDrive/Final_Project/speech_recognition/baseline_4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HI7eQrAmu-c",
        "outputId": "c3abcb6c-2c9d-4b38-9792-33dc78774f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step - loss: 0.3177 - recall_1: 0.1875 - precision_1: 0.3750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31772035360336304, 0.1875, 0.375]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X_test, y_test = test_data.as_numpy_iterator().next()\n",
        "\n",
        "base_model_loaded.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXTLDBumnHh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6885ff62-32ca-470a-c669-79036e1bb574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 332ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.56      0.69        50\n",
            "           1       0.50      0.20      0.29        50\n",
            "           2       0.48      0.30      0.37        50\n",
            "           3       0.69      0.48      0.56        50\n",
            "           4       0.78      0.42      0.55        50\n",
            "           5       0.75      0.60      0.67        50\n",
            "           6       0.70      0.38      0.49        50\n",
            "           7       0.89      0.68      0.77        50\n",
            "           8       0.65      0.82      0.73        50\n",
            "           9       0.50      0.62      0.55        50\n",
            "          10       0.38      0.90      0.53        50\n",
            "          11       0.58      0.70      0.64        50\n",
            "          12       0.37      0.72      0.49        50\n",
            "\n",
            "    accuracy                           0.57       650\n",
            "   macro avg       0.63      0.57      0.56       650\n",
            "weighted avg       0.63      0.57      0.56       650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create empty arrays/lists for true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate over the test dataset and make predictions\n",
        "for x, y in test_data:\n",
        "    # Predict the labels using the trained model\n",
        "    predictions = base_model_loaded.predict(x)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Store the true labels and predicted labels\n",
        "    y_true.extend(np.argmax(y, axis=1))\n",
        "    y_pred.extend(predicted_labels)\n",
        "\n",
        "# Convert the true labels and predicted labels to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model with dropout added**"
      ],
      "metadata": {
        "id": "JqQPkLl1Wu3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_new = Sequential()\n",
        "base_model_new.add(Conv2D(16, (3, 3), activation='relu', input_shape=(491, 257, 1)))\n",
        "base_model_new.add(Dropout(0.25))\n",
        "base_model_new.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "base_model_new.add(Flatten())\n",
        "base_model_new.add(Dense(128, activation='relu'))\n",
        "base_model_new.add(Dropout(0.5))\n",
        "base_model_new.add(Dense(13, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "QfLYWd2tDUHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_new.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(),tf.keras.metrics.Accuracy() ])"
      ],
      "metadata": {
        "id": "eIB_6_W9Eew3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = base_model_new.fit(train_data, validation_data=val_data, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdbQZLDsDbHb",
        "outputId": "65bfa7ed-70fe-444b-a293-6e2ce261f818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "324/324 [==============================] - 106s 227ms/step - loss: 0.4399 - recall: 0.0688 - precision: 0.1853 - accuracy: 0.0053 - val_loss: 0.5542 - val_recall: 0.0369 - val_precision: 0.3243 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/15\n",
            "324/324 [==============================] - 35s 108ms/step - loss: 0.2325 - recall: 0.1800 - precision: 0.4854 - accuracy: 1.4876e-05 - val_loss: 0.4337 - val_recall: 0.1108 - val_precision: 0.5455 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/15\n",
            "324/324 [==============================] - 35s 107ms/step - loss: 0.1906 - recall: 0.3193 - precision: 0.6299 - accuracy: 4.4628e-05 - val_loss: 0.2529 - val_recall: 0.2354 - val_precision: 0.5564 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/15\n",
            "324/324 [==============================] - 34s 106ms/step - loss: 0.1576 - recall: 0.4305 - precision: 0.7158 - accuracy: 1.7851e-04 - val_loss: 0.2217 - val_recall: 0.2446 - val_precision: 0.6310 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/15\n",
            "324/324 [==============================] - 35s 107ms/step - loss: 0.1344 - recall: 0.5307 - precision: 0.7593 - accuracy: 4.0165e-04 - val_loss: 0.2235 - val_recall: 0.2815 - val_precision: 0.6606 - val_accuracy: 1.1834e-04\n",
            "Epoch 6/15\n",
            "324/324 [==============================] - 34s 106ms/step - loss: 0.1139 - recall: 0.6009 - precision: 0.8033 - accuracy: 7.4379e-04 - val_loss: 0.1994 - val_recall: 0.2800 - val_precision: 0.6868 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/15\n",
            "324/324 [==============================] - 34s 105ms/step - loss: 0.0995 - recall: 0.6722 - precision: 0.8356 - accuracy: 0.0018 - val_loss: 0.2197 - val_recall: 0.2538 - val_precision: 0.6157 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/15\n",
            "324/324 [==============================] - 35s 108ms/step - loss: 0.0893 - recall: 0.7140 - precision: 0.8462 - accuracy: 0.0021 - val_loss: 0.2100 - val_recall: 0.2631 - val_precision: 0.6502 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/15\n",
            "324/324 [==============================] - 35s 108ms/step - loss: 0.0776 - recall: 0.7612 - precision: 0.8702 - accuracy: 0.0024 - val_loss: 0.2192 - val_recall: 0.1954 - val_precision: 0.6684 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/15\n",
            "324/324 [==============================] - 34s 105ms/step - loss: 0.0727 - recall: 0.7813 - precision: 0.8806 - accuracy: 0.0042 - val_loss: 0.2503 - val_recall: 0.2292 - val_precision: 0.7095 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/15\n",
            "324/324 [==============================] - 35s 107ms/step - loss: 0.0671 - recall: 0.8055 - precision: 0.9005 - accuracy: 0.0046 - val_loss: 0.2468 - val_recall: 0.2492 - val_precision: 0.6807 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/15\n",
            "324/324 [==============================] - 34s 105ms/step - loss: 0.0589 - recall: 0.8406 - precision: 0.9051 - accuracy: 0.0056 - val_loss: 0.2371 - val_recall: 0.2385 - val_precision: 0.7176 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/15\n",
            "324/324 [==============================] - 35s 107ms/step - loss: 0.0536 - recall: 0.8550 - precision: 0.9228 - accuracy: 0.0062 - val_loss: 0.2255 - val_recall: 0.2169 - val_precision: 0.7268 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/15\n",
            "324/324 [==============================] - 34s 104ms/step - loss: 0.0465 - recall: 0.8640 - precision: 0.9252 - accuracy: 0.0090 - val_loss: 0.2779 - val_recall: 0.2123 - val_precision: 0.7077 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/15\n",
            "324/324 [==============================] - 35s 107ms/step - loss: 0.0506 - recall: 0.8728 - precision: 0.9284 - accuracy: 0.0102 - val_loss: 0.2671 - val_recall: 0.2323 - val_precision: 0.7402 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_new.save('/content/gdrive/MyDrive/Final_Project/speech_recognition/base_model_new_15')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3uGwG6HL3vW",
        "outputId": "86c5437a-aa2a-4b87-e0fe-e7e1e411459b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "base_model_new_15_loaded = load_model('/content/gdrive/MyDrive/Final_Project/speech_recognition/base_model_new_15')"
      ],
      "metadata": {
        "id": "l9AtZuSTMBV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = test_data.as_numpy_iterator().next()\n",
        "\n",
        "base_model_new_15_loaded.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXfjueQTWpiU",
        "outputId": "f849679d-69b6-4d93-91fe-15fe2b618aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step - loss: 0.3294 - recall: 0.1875 - precision: 0.7500 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32944822311401367, 0.1875, 0.75, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create empty arrays/lists for true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate over the test dataset and make predictions\n",
        "for x, y in test_data:\n",
        "    # Predict the labels using the trained model\n",
        "    predictions = base_model_new_15_loaded.predict(x)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Store the true labels and predicted labels\n",
        "    y_true.extend(np.argmax(y, axis=1))\n",
        "    y_pred.extend(predicted_labels)\n",
        "\n",
        "# Convert the true labels and predicted labels to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "CutyEamwX7W0",
        "outputId": "f43032e5-3ed4-497f-a196-238ce7233234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 404ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 354ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67        50\n",
            "           1       0.42      0.26      0.32        50\n",
            "           2       0.64      0.14      0.23        50\n",
            "           3       0.50      0.26      0.34        50\n",
            "           4       0.47      0.36      0.41        50\n",
            "           5       0.61      0.46      0.52        50\n",
            "           6       0.55      0.46      0.50        50\n",
            "           7       0.83      0.58      0.68        50\n",
            "           8       0.62      0.72      0.67        50\n",
            "           9       0.51      0.72      0.60        50\n",
            "          10       0.31      0.70      0.43        50\n",
            "          11       0.47      0.68      0.56        50\n",
            "          12       0.30      0.46      0.37        50\n",
            "\n",
            "    accuracy                           0.49       650\n",
            "   macro avg       0.54      0.49      0.48       650\n",
            "weighted avg       0.54      0.49      0.48       650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AlexNet Format**"
      ],
      "metadata": {
        "id": "8RLolVpon5xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_alex_net = Sequential()\n",
        "\n",
        "# Layer 1\n",
        "base_model_alex_net.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(491, 257, 1)))\n",
        "base_model_alex_net.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "# Layer 2\n",
        "base_model_alex_net.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "base_model_alex_net.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "# Layer 3\n",
        "base_model_alex_net.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Layer 4\n",
        "base_model_alex_net.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "# Layer 5\n",
        "base_model_alex_net.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "base_model_alex_net.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "base_model_alex_net.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "base_model_alex_net.add(Dense(4096, activation='relu'))\n",
        "base_model_alex_net.add(Dropout(0.5))\n",
        "\n",
        "base_model_alex_net.add(Dense(4096, activation='relu'))\n",
        "base_model_alex_net.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "base_model_alex_net.add(Dense(13, activation='softmax'))"
      ],
      "metadata": {
        "id": "HSvfvHpdn8jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_alex_net.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.Accuracy()])\n"
      ],
      "metadata": {
        "id": "t91ZHh02pwgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_alex_net.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wuD6202qI0F",
        "outputId": "a7a66cff-94f6-427f-db7b-4456015f2c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 121, 62, 96)       11712     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 60, 30, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 60, 30, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 29, 14, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 29, 14, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 29, 14, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 29, 14, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 14, 6, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 21504)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              88084480  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 13)                53261     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108,643,021\n",
            "Trainable params: 108,643,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = base_model_alex_net.fit(train_data, validation_data=val_data, epochs=6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiiyS5lErHFI",
        "outputId": "1aa6ef4c-fd5c-4144-d8f3-bfb3ce345641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "324/324 [==============================] - 3733s 11s/step - loss: 0.2520 - recall: 0.0043 - precision: 0.2292 - accuracy: 0.0000e+00 - val_loss: 0.3099 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/6\n",
            "324/324 [==============================] - 18s 55ms/step - loss: 0.2485 - recall: 0.0000e+00 - precision: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.3031 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/6\n",
            "324/324 [==============================] - 18s 55ms/step - loss: 0.2508 - recall: 0.0000e+00 - precision: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.3061 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/6\n",
            "324/324 [==============================] - 18s 55ms/step - loss: 0.2523 - recall: 0.0000e+00 - precision: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.2944 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/6\n",
            "324/324 [==============================] - 18s 55ms/step - loss: 0.2520 - recall: 0.0000e+00 - precision: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.3088 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/6\n",
            "324/324 [==============================] - 18s 55ms/step - loss: 0.2595 - recall: 0.0000e+00 - precision: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.3052 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_alex_net.save('/content/gdrive/MyDrive/Final_Project/speech_recognition/alex_net_6')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM-yD51srXg-",
        "outputId": "bd212430-f8c9-4d06-ef45-e84cb3361f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdc8PDbL6Flo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}