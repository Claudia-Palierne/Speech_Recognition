{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1MPivN4HEjJ",
        "outputId": "5b2c4538-6d77-40bb-cac7-4fd36b649f0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io) (0.32.0)\n",
            "Installing collected packages: tensorflow_io\n",
            "Successfully installed tensorflow_io-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wave\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import IPython.display as ipd\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "Wqur42BLZEq3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Recognition"
      ],
      "metadata": {
        "id": "49nqFdV8Af7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path = 'drive/MyDrive/Kaggle/speech_recognition/'\n",
        "\n",
        "path = '/content/gdrive/MyDrive/speech_recognition/'\n",
        "classes = ['yes', 'no', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'up', 'down']"
      ],
      "metadata": {
        "id": "hAIDWjjAAnKs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ARNKkPVtjf",
        "outputId": "59848cb2-a6db-44ad-ba5e-82f7d4ebef52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building dataset"
      ],
      "metadata": {
        "id": "vgmJV9NX-jIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Paths to labeled data and Split into Train, Validation and Test using Kaggle split\n",
        "tf_dic_train = {}\n",
        "tf_dic_val = {}\n",
        "tf_dic_test = {}\n",
        "FILES_TO_LOAD = 500\n",
        "\n",
        "with open(os.path.join(path + \"/testing_list.txt\"), 'r') as file:\n",
        "    test_names = file.read().splitlines()\n",
        "with open(os.path.join(path + \"/validation_list.txt\"), 'r') as file:\n",
        "    val_names = file.read().splitlines()\n",
        "\n",
        "for i, label in enumerate(classes):\n",
        "  train_tmp = []\n",
        "  val_tmp = []\n",
        "  test_tmp = []\n",
        "  for filename in os.listdir(os.path.join(path + label)):\n",
        "    if \"/\".join([label, filename]) in test_names:\n",
        "      if len(test_tmp) >= FILES_TO_LOAD*0.1:\n",
        "        pass\n",
        "      else:\n",
        "        test_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "    elif \"/\".join([label, filename]) in val_names:\n",
        "      if len(val_tmp) >= FILES_TO_LOAD*0.1:\n",
        "        pass\n",
        "      else:\n",
        "        val_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "    else:\n",
        "      if len(train_tmp) >= FILES_TO_LOAD*0.8:\n",
        "        pass\n",
        "      else:\n",
        "        train_tmp.append(os.path.join(path + label + \"/\" + filename))\n",
        "\n",
        "  train_tmp_tf = tf.data.Dataset.list_files(train_tmp)\n",
        "  val_tmp_tf = tf.data.Dataset.list_files(val_tmp)\n",
        "  test_tmp_tf = tf.data.Dataset.list_files(test_tmp)\n",
        "\n",
        "  tf_dic_train[label] = tf.data.Dataset.zip((train_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(train_tmp_tf),), i))))\n",
        "  tf_dic_val[label] = tf.data.Dataset.zip((val_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(val_tmp_tf),), i))))\n",
        "  tf_dic_test[label] = tf.data.Dataset.zip((test_tmp_tf, tf.data.Dataset.from_tensor_slices(tf.fill((len(test_tmp_tf),), i))))\n",
        "\n",
        "datasets_train = list(tf_dic_train.values())\n",
        "datasets_val = list(tf_dic_val.values())\n",
        "datasets_test = list(tf_dic_test.values())"
      ],
      "metadata": {
        "id": "-rCkMSM1lGMD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_reduce(datasets):\n",
        "  merged_dataset_reduce = reduce(lambda d1, d2: d1.concatenate(d2), datasets)\n",
        "  return merged_dataset_reduce.shuffle(buffer_size=1000)"
      ],
      "metadata": {
        "id": "CeOND8VnxWAi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_train = dataset_reduce(datasets_train)\n",
        "datasets_val = dataset_reduce(datasets_val)\n",
        "datasets_test = dataset_reduce(datasets_test)"
      ],
      "metadata": {
        "id": "qp88sR5exlkC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(datasets_train), len(datasets_val), len(datasets_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApnE-Lh_yCc-",
        "outputId": "0d9691fa-f953-43c5-efd3-3f23803b2d9f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5171, 650, 650)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "_gNU6oDy-dRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels)\n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ],
      "metadata": {
        "id": "fDwJKqP-veEG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load padding wav file from _noice folder (/content/gdrive/MyDrive/speech_recognition/_noise/dude_miaowing.wav)\n",
        "padding_file = '/content/gdrive/MyDrive/speech_recognition/_noise/dude_miaowing.wav'\n",
        "padding_contents = tf.io.read_file(padding_file)\n",
        "padding_waveform, _ = tf.audio.decode_wav(padding_contents, desired_channels=1)\n",
        "padding_waveform = tf.squeeze(padding_waveform, axis=-1)"
      ],
      "metadata": {
        "id": "J3nFfroB3j1a"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_multy(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:16000]\n",
        "\n",
        "    # Calculate difference in length\n",
        "    target_length = 16000\n",
        "    current_length = tf.shape(wav)[0]\n",
        "    pad_length = target_length - current_length\n",
        "\n",
        "    # Pad waveform if it is shorter than the target length\n",
        "    if pad_length > 0:\n",
        "        padding_start = tf.random.uniform(shape=[], minval=0, maxval=padding_waveform.shape[0] - pad_length, dtype=tf.int32)\n",
        "        padding_slice = padding_waveform[padding_start : padding_start + pad_length]\n",
        "\n",
        "        # Pad the waveform with the selected slice\n",
        "        wav = tf.concat([wav, padding_slice], axis=0)\n",
        "\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, tf.one_hot(label, 13)"
      ],
      "metadata": {
        "id": "48W8Ev9yPOns"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data:\n",
        "train_data = datasets_train.map(preprocess_multy)\n",
        "train_data = train_data.cache()\n",
        "train_data = train_data.shuffle(buffer_size=1000)\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ],
      "metadata": {
        "id": "m1DC4ZrfPP0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ac0973-cc95-41ed-a0ae-7484ef41887b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation data:\n",
        "val_data = datasets_val.map(preprocess_multy)\n",
        "val_data = val_data.cache()\n",
        "val_data = val_data.shuffle(buffer_size=1000)\n",
        "val_data = val_data.batch(16)\n",
        "val_data = val_data.prefetch(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5nWR3N5M-W",
        "outputId": "c25ae44a-e773-4cdc-adab-2104efc2b0c8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data:\n",
        "test_data = datasets_test.map(preprocess_multy)\n",
        "test_data = test_data.cache()\n",
        "test_data = test_data.shuffle(buffer_size=1000)\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilWusoI5ZUV",
        "outputId": "8ff39282-2fcb-43de-be1f-7f185f894952"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(val_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P_zV44143yj",
        "outputId": "ce455ad4-6b2a-40f4-d05e-1d8571d4cd85"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(324, 41, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = train_data.as_numpy_iterator().next()\n",
        "samples.shape, labels.shape"
      ],
      "metadata": {
        "id": "cA9AQKXIRbCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70f9c419-57ca-4eb5-f1c9-f026df5dfccf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 491, 257, 1), (16, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}